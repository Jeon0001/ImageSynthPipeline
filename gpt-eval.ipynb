{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SulVcFxBfkM5"
   },
   "source": [
    "## Evaluating GPT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9334,
     "status": "ok",
     "timestamp": 1730699848335,
     "user": {
      "displayName": "Kyaw Ye Thu",
      "userId": "15265666706494287045"
     },
     "user_tz": -540
    },
    "id": "ncrDxjOAWxLg",
    "outputId": "78999fa1-4b4e-4f11-cde7-3b5af08c1ea9"
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import sys\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "else:\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "up6nALBDWf2B"
   },
   "outputs": [],
   "source": [
    "# Path to your image\n",
    "image_path = \"images/synthesized_images/Azerbaijan/Black/Azerbaijan_clothes_black_0.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Which country is the clothing in the photo mostly associated with? Which visual cues helped you make this determination?\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\":  f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "\n",
    "image = plt.imread(image_path)\n",
    "plt.imshow(image)\n",
    "plt.axis('off') \n",
    "plt.show()\n",
    "\n",
    "print(f\"Filename: {os.path.basename(image_path)}\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a request for each image\n",
    "def process_images_in_batch(image_folder, client, max_images=10):\n",
    "    # List all image files in the directory\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    num_images_processed = 0\n",
    "    responses = []\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        if num_images_processed >= max_images:\n",
    "            break\n",
    "        num_images_processed += 1\n",
    "        \n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        base64_image = encode_image(image_path)\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"Which country is the clothing in the photo mostly associated with? Which visual cues helped you make this determination?\",                                \n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                },\n",
    "                            },\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_file}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        responses.append({\n",
    "            \"image_file\": image_file,\n",
    "            \"response\": response.choices[0]\n",
    "        })\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def print_save_responses(responses, image_folder, save=True): \n",
    "    json_output = os.path.basename(image_folder) + \".json\"\n",
    "    data_to_save = []\n",
    "        \n",
    "    # Output the results\n",
    "    for response in responses:\n",
    "        image_path = os.path.join(image_folder, response['image_file'])\n",
    "        message_content = response['response'].message.content\n",
    "\n",
    "        # Append data for each response\n",
    "        if save: \n",
    "            data_to_save.append({\n",
    "                \"image_file\": image_path,\n",
    "                \"message\": message_content\n",
    "            })\n",
    "        \n",
    "        # Display the image\n",
    "        image = plt.imread(image_path)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off') \n",
    "        plt.show()\n",
    "\n",
    "        # Print the formatted message and file name\n",
    "        print(f\"Filename: {os.path.basename(image_path)}\")\n",
    "        print(message_content)\n",
    "        print(\"=\" * 50)\n",
    "    \n",
    "    if save:\n",
    "        with open(json_output, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data_to_save, f, indent=4)\n",
    "\n",
    "        print(f\"Data saved to: {json_output}\")\n",
    "\n",
    "\n",
    "image_folder = \"images/synthesized_images/Azerbaijan/copy\"\n",
    "responses = process_images_in_batch(image_folder, client)\n",
    "print_save_responses(responses, image_folder, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Files (If needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all the files in the folder\n",
    "image_folder = 'images/synthesized_images/Azerbaijan/Indian'\n",
    "\n",
    "for i, filename in enumerate(os.listdir(image_folder)):\n",
    "    # check if the file name ends with .png\n",
    "    if filename.endswith('.png'):\n",
    "        os.rename(os.path.join(image_folder, filename), os.path.join(image_folder, f\"Azerbaijan_clothes_indian_{i}.png\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
