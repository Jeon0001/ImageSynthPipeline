{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SulVcFxBfkM5"
   },
   "source": [
    "## Evaluating GPT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9334,
     "status": "ok",
     "timestamp": 1730699848335,
     "user": {
      "displayName": "Kyaw Ye Thu",
      "userId": "15265666706494287045"
     },
     "user_tz": -540
    },
    "id": "ncrDxjOAWxLg",
    "outputId": "78999fa1-4b4e-4f11-cde7-3b5af08c1ea9"
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this file locally, make sure to save openai api key in `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "from openai import OpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "else:\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for batch evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a request for each image\n",
    "def process_images_in_batch(image_folder, prompt, client, verbose=True):\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    responses = []\n",
    "    \n",
    "    for image_file in image_files:        \n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        base64_image = encode_image(image_path)\n",
    "        \n",
    "        # temporary code to skip first 10 images\n",
    "        index = int(image_file.split('_')[-1].split('.')[0])\n",
    "        if index < 10:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt,                                \n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                },\n",
    "                            },\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_file}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Filename: {image_file}| Response: {response.choices[0].message.content}\")\n",
    "            \n",
    "        responses.append({\"image_file\": image_file,\"response\": response.choices[0].message.content})\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def save_responses(responses, image_folder, csv_file_path, first_write=True, verbose=False):          \n",
    "    ### The file needs to exist if it's not the first write \n",
    "    if not first_write and not os.path.exists(csv_file_path):\n",
    "        print(\"Please provide a valid CSV file path.\")\n",
    "        return\n",
    "    \n",
    "    ### determining original_country and synthesized_race automatically from the folder name\n",
    "    possible_countries = ['Korea', 'UK', 'Myanmar', 'Azerbaijan']\n",
    "    possible_synthesized_races = ['Asian', 'Indian', 'Black', 'White', 'Caucasian']\n",
    "\n",
    "    original_country = [country for country in possible_countries if country in image_folder][0]\n",
    "\n",
    "    if 'original' in image_folder:\n",
    "        synthesized_race = original_country\n",
    "    else:\n",
    "        synthesized_race = [race for race in possible_synthesized_races if race in image_folder][0]\n",
    "    \n",
    "    ### saving into the csv file\n",
    "    with open(csv_file_path, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write the header if it's the first write\n",
    "        if first_write:\n",
    "            csv_writer.writerow(['original_country', 'synthesized_race', 'image_file_name', 'response'])\n",
    "\n",
    "        # Write each response \n",
    "        for response in responses:\n",
    "            # you would have to manually change original_country and synthesized_race for each run\n",
    "            csv_writer.writerow([original_country, synthesized_race, response['image_file'], response['response']])\n",
    "            \n",
    "            if verbose: print(f\"Filename: {response['image_file']} | Response: {response['response']}\")\n",
    "            \n",
    "        print(f\"Data saved to: {csv_file_path}\")\n",
    "        \n",
    "    ### sort the rows in the .csv file by file index\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df[\"index\"] = df[\"image_file_name\"].apply(lambda file_name: int(file_name.split(\"_\")[-1].split(\".\")[0]))\n",
    "    df_sorted = df.sort_values(by=[\"synthesized_race\", \"index\"], ascending=[True, True])\n",
    "    df_sorted = df_sorted.drop(columns=[\"index\"])\n",
    "    df_sorted.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate all images inside a given directory and save the responses in a given `.csv` file.\n",
    "- Set `first_write=True` if writing responses into a new file and needing the **header row** like `'original_country', 'synthesized_race', 'image_file_name', 'response'`.\n",
    "- The function will automatically figure out `original_country` and `synthesized_race` from `image_folder`, so ensure the folder path name is meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"images/synthesized_images/clothes/Myanmar/Indian\"\n",
    "prompt = \"Which country is the clothing in the photo mostly associated with? Which visual cues did you use to determine it?\"\n",
    "responses = process_images_in_batch(image_folder, prompt, client)\n",
    "\n",
    "csv_file_path = \"responses/Myanmar_Indian_Clothes_Results.csv\"\n",
    "save_responses(responses, image_folder, csv_file_path, first_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "up6nALBDWf2B"
   },
   "outputs": [],
   "source": [
    "# Path to your image\n",
    "image_path = \"images/synthesized_images/food/Myanmar/Asian/Myanmar_Asian_food_5.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Which country is the food in the photo mostly associated with? What is this food called?\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\":  f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "\n",
    "image = plt.imread(image_path)\n",
    "plt.imshow(image)\n",
    "plt.axis('off') \n",
    "plt.show()\n",
    "\n",
    "print(f\"Filename: {os.path.basename(image_path)}\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
