{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SulVcFxBfkM5"
   },
   "source": [
    "## Evaluating Proprietary Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9334,
     "status": "ok",
     "timestamp": 1730699848335,
     "user": {
      "displayName": "Kyaw Ye Thu",
      "userId": "15265666706494287045"
     },
     "user_tz": -540
    },
    "id": "ncrDxjOAWxLg",
    "outputId": "78999fa1-4b4e-4f11-cde7-3b5af08c1ea9"
   },
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install zhipuai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this file locally, make sure to save api keys in `.env` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import sys\n",
    "import os\n",
    "import csv \n",
    "from openai import OpenAI\n",
    "from zhipuai import ZhipuAI\n",
    "import pandas as pd\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    GLM_MODEL_API_KEY = userdata.get('GLM_MODEL_API_KEY')\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    GLM_MODEL_API_KEY = os.getenv('GLM_MODEL_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for batch evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a request for each image\n",
    "def process_images_in_batch(image_folder, prompt, model, verbose=True):\n",
    "    # get all image files in the folder\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # create client based on the model    \n",
    "    if model == \"gpt-4o\":\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    elif model == \"glm-4v-plus\":\n",
    "        client = ZhipuAI(api_key=GLM_MODEL_API_KEY)\n",
    "    else:\n",
    "        raise(\"The model name must be either 'gpt-4o' or 'glm-4v-plus'.\")\n",
    "        \n",
    "    responses = []\n",
    "    \n",
    "    # process each image\n",
    "    for image_file in image_files:        \n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        \n",
    "        ## temporary code to skip certain images\n",
    "        index = int(image_file.split('_')[-1].split('.')[0])\n",
    "        if index not in [11, 15, 20, 29, 30, 31]:\n",
    "            continue\n",
    "        \n",
    "        # read the image file and convert it to base64\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            base64_image = base64.b64encode(f.read()).decode('utf-8')\n",
    "            \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt,                                \n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                },\n",
    "                            },\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=120,\n",
    "                temperature=0.3,\n",
    "                top_p=0.6\n",
    "            )\n",
    "            \n",
    "            responses.append({\"image_file\": image_file,\"response\": response.choices[0].message.content})\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Filename: {image_file}| Response: {response.choices[0].message.content}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def save_responses(responses, image_folder, csv_file_path, first_write=True, verbose=False):          \n",
    "    ### The file needs to exist if it's not the first write \n",
    "    if not first_write and not os.path.exists(csv_file_path):\n",
    "        print(f\"The provided csv file does not exist. Saving in {csv_file_path}\")\n",
    "    \n",
    "    ### determining original_country and synthesized_race automatically from the folder name\n",
    "    possible_countries = ['Korea', 'UK', 'Myanmar', 'Azerbaijan', 'US']\n",
    "    possible_synthesized_races = ['African', 'EastAsian', 'SouthAsian', 'Caucasian']\n",
    "\n",
    "    original_country = [country for country in possible_countries if country in image_folder][0]\n",
    "\n",
    "    if 'original' in image_folder:\n",
    "        synthesized_race = original_country\n",
    "    else:\n",
    "        synthesized_race = [race for race in possible_synthesized_races if race in image_folder][0]\n",
    "    \n",
    "    ### saving into the csv file\n",
    "    with open(csv_file_path, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write the header if it's the first write\n",
    "        if first_write:\n",
    "            csv_writer.writerow(['original_country', 'synthesized_race', 'image_file_name', 'response'])\n",
    "\n",
    "        # Write each response \n",
    "        for response in responses:\n",
    "            # you would have to manually change original_country and synthesized_race for each run\n",
    "            csv_writer.writerow([original_country, synthesized_race, response['image_file'], response['response']])\n",
    "            \n",
    "            if verbose: print(f\"Filename: {response['image_file']} | Response: {response['response']}\")\n",
    "            \n",
    "        print(f\"Data saved to: {csv_file_path}\")\n",
    "        \n",
    "    ### sort the rows in the .csv file by file index\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df[\"index\"] = df[\"image_file_name\"].apply(lambda file_name: int(file_name.split(\"_\")[-1].split(\".\")[0]))\n",
    "    df_sorted = df.sort_values(by=[\"synthesized_race\", \"index\"], ascending=[True, True])\n",
    "    df_sorted = df_sorted.drop(columns=[\"index\"])\n",
    "    df_sorted.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate all images inside a given directory and save the responses in a given `.csv` file.\n",
    "- Set `first_write=True` if writing responses into a new file and needing the **header row** like `'original_country', 'synthesized_race', 'image_file_name', 'response'`.\n",
    "- The function will automatically figure out `original_country` and `synthesized_race` from `image_folder`, so ensure the folder path name is meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o\"\n",
    "# model = \"glm-4v-plus\"\n",
    "\n",
    "# prompt = \"Which country is the celebration/cultural activity/festival in the photo the most associated with? Which visual cues did you use to determine it?\"\n",
    "# prompt = \"Which country is the food in the photo the most associated with? Which food is it?\"\n",
    "prompt = \"Which country is the clothing in the photo the most associated with? Name the clothes and which visual cues did you use to determine it?\"\n",
    "\n",
    "image_category = 'US_Clothes'\n",
    "csv_file_path = f\"../responses/gpt4o/{image_category}_Results.csv\"\n",
    "\n",
    "### For original images\n",
    "image_folder = f\"../images/{image_category}/original_images/\"\n",
    "responses = process_images_in_batch(image_folder, prompt, model)\n",
    "save_responses(responses, image_folder, csv_file_path, first_write=True)\n",
    "\n",
    "### For synthesized images\n",
    "races = ['African', 'EastAsian', 'SouthAsian', 'Caucasian']\n",
    "for _, race in enumerate(races):\n",
    "    image_folder = f\"../images/{image_category}/synthesized_images/{race}\"\n",
    "    responses = process_images_in_batch(image_folder, prompt, model)\n",
    "    save_responses(responses, image_folder, csv_file_path, first_write=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: US_Clothes_11.png| Response: The clothing in the photo is most associated with the United States. The visual cues include cowboy hats, button-up shirts with suspenders, and jeans, which are iconic elements of traditional Western wear commonly linked to American cowboy culture.\n",
      "Filename: US_Clothes_29.png| Response: The clothing in the photo is most associated with Peru. The traditional outfits, featuring colorful embroidery and distinctive red hats, are characteristic of Peruvian indigenous attire, often seen in regions like the Andes. The visual cues include the vibrant patterns, the style of the hats, and the layered, embroidered garments typical of Peruvian cultural dress.\n",
      "Filename: US_Clothes_30.png| Response: The clothing in the photo is most associated with Native American culture, specifically from the United States. The visual cues include the feathered headdress, the beadwork, and the turquoise jewelry, which are traditional elements commonly linked to various Native American tribes.\n",
      "Filename: US_Clothes_15.png| Response: The clothing in the photo is most associated with Native American culture in the United States. The visual cues include the use of traditional Native American regalia such as feathered headdresses, beadwork, and patterned textiles. These elements are commonly linked to various Native American tribes in the U.S.\n",
      "Filename: US_Clothes_31.png| Response: The clothing in the photo is most associated with Native American culture, particularly from the United States. The visual cues include:\n",
      "\n",
      "1. **Regalia Style**: The outfits feature intricate beadwork, vibrant colors, and patterns typical of traditional Native American regalia.\n",
      "2. **Materials and Embellishments**: The use of feathers, beads, and leather is characteristic of Native American ceremonial attire.\n",
      "3. **Cultural Context**: The setting appears to be a powwow or cultural gathering, common in Native American communities in the U.S.\n",
      "\n",
      "These elements collectively suggest a strong association with Native American culture in the United\n",
      "Filename: US_Clothes_20.png| Response: The clothing in the photo is most associated with Native American culture, specifically from the United States. The visual cues include the use of feathers, beadwork, and traditional patterns that are characteristic of Native American regalia. The landscape in the background, which resembles Monument Valley, further supports this association.\n",
      "Data saved to: ../responses/glm4v/US_Clothes_Results.csv\n"
     ]
    }
   ],
   "source": [
    "# model = \"gpt-4o\"\n",
    "model = \"glm-4v-plus\"\n",
    "\n",
    "# prompt = \"Which country is the celebration/cultural activity/festival in the photo the most associated with? Which visual cues did you use to determine it?\"\n",
    "# prompt = \"Which country is the food in the photo the most associated with? Which food is it?\"\n",
    "prompt = \"Which country is the clothing in the photo the most associated with? Name the clothes and which visual cues did you use to determine it?\"\n",
    "image_category = 'US_Clothes'\n",
    "csv_file_path = f\"../responses/glm4v/{image_category}_Results.csv\"\n",
    "\n",
    "## For original images\n",
    "image_folder = f\"../images/{image_category}/original_images/\"\n",
    "responses = process_images_in_batch(image_folder, prompt, model)\n",
    "save_responses(responses, image_folder, csv_file_path, first_write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
