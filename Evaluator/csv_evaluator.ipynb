{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(y_true, y_pred, round_digits=3):\n",
    "    precision = round(precision_score(y_true, y_pred, zero_division=0), round_digits)\n",
    "    recall    = round(recall_score(y_true, y_pred, zero_division=0), round_digits)\n",
    "    f1        = round(f1_score(y_true, y_pred, zero_division=0), round_digits)\n",
    "    accuracy  = round(accuracy_score(y_true, y_pred), round_digits)\n",
    "    \n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "# Custom sorting function\n",
    "def custom_sort(df):\n",
    "    # Assign a priority column for sorting\n",
    "    df['priority'] = df.apply(\n",
    "        lambda row: 0 if row['Country'] == row['Race'] else 1 \n",
    "                    if row['Race'] != 'total' else 2, axis=1\n",
    "    )\n",
    "    # Sort by Country, then by priority, and reset index\n",
    "    df = df.sort_values(by=['Country', 'priority']).drop(columns='priority').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def consolidate_one_country_name(country_name):\n",
    "    if country_name.startswith('American'):\n",
    "        return 'US'\n",
    "    elif country_name.startswith('Britain'):\n",
    "        return 'UK'\n",
    "\n",
    "def highlight_row(row):\n",
    "    if row['Country'] == row['Race']:\n",
    "        return ['background-color: #690150'] * len(row) # data for original images are red\n",
    "    \n",
    "    if row['Race'] == 'Synthesized Total':\n",
    "        return ['background-color: #016950'] * len(row) # data for total images are green\n",
    "    \n",
    "    return [''] * len(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cultural Identification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cultural_identification_metrics(file_path, race_verbose=True, misclassified_verbose=False):\n",
    "    # 1. Load the data\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 2. Create 'Match' column. Match if `original_country` is mentioned in the `response`\n",
    "    data['Match_country'] = data.apply(\n",
    "        lambda row: 1 if any(term.lower().strip() in row['response'].lower() for term in row['original_country'].split(',')) else 0, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 3. Normalize the text of both `original_country` to ensure consistent grouping (e.g., remove duplicates, ordering effect, etc.)\n",
    "    data['original_country'] = data['original_country'].apply(lambda x: ', '.join(sorted(set(term.strip() for term in x.split(',')))))        \n",
    "\n",
    "    data['original_country'] = data['original_country'].apply(consolidate_one_country_name) \n",
    "    \n",
    "    # Get unique combinations of country and race\n",
    "    unique_combinations = data.groupby(['original_country', 'synthesized_race']).size().reset_index()\n",
    "    unique_combinations.columns = ['original_country', 'synthesized_race', 'count']\n",
    "    \n",
    "    unique_countries = data['original_country'].unique()\n",
    "    \n",
    "    # Initialize results\n",
    "    country_results = []\n",
    "    misclassified_images = []\n",
    "        \n",
    "    # Add a row for the 'total'\n",
    "    for country in unique_countries:\n",
    "        # if there is only one synthesized_race for a country in unique_combinations, then skip adding 'total' row\n",
    "        if len(unique_combinations[unique_combinations['original_country'] == country]) > 1:\n",
    "            new_row = {'original_country': country, 'synthesized_race': 'Synthesized Total', 'count': 0}\n",
    "            unique_combinations = pd.concat([unique_combinations, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "\n",
    "    # Compute metrics for each country-race combination\n",
    "    for index, row in unique_combinations.iterrows():\n",
    "        country = row['original_country']\n",
    "        race = row['synthesized_race']\n",
    "        \n",
    "        if race == 'Synthesized Total':\n",
    "            subset = data[(data['original_country'] == country) & (data['original_country'] != data['synthesized_race'])]\n",
    "        else:\n",
    "            subset = data[(data['original_country'] == country) & (data['synthesized_race'] == race)]\n",
    "        \n",
    "        y_true = [1] * len(subset)  # Ground truth: should mention the country\n",
    "        y_pred = subset['Match_country'].tolist()\n",
    "\n",
    "        precision, recall, f1, accuracy = calculate_scores(y_true, y_pred)                \n",
    "\n",
    "        # Identify misclassified samples\n",
    "        if race != 'total':\n",
    "            misclassified_indices = [i + (row['count'] * index) for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true != pred]  \n",
    "            misclassified_images.extend(data.iloc[misclassified_indices]['image_file_name'].tolist())\n",
    "                \n",
    "        country_results.append({\n",
    "            'Country': country,\n",
    "            'Race': race,\n",
    "            # 'Precision': precision,\n",
    "            # 'Recall': recall,\n",
    "            # 'F1 Score': f1,\n",
    "            'Accuracy': accuracy,\n",
    "            'Correct Samples': sum(y_pred),    # sum of 1s\n",
    "            'Total Samples': len(subset)      # total rows in this group\n",
    "        })\n",
    "\n",
    "    if misclassified_verbose:\n",
    "            print(f\"Misclassified images: {misclassified_images}\")\n",
    "            misclassified_data = data[data['image_file_name'].isin(misclassified_images)]\n",
    "            misclassified_indices = misclassified_data.index.tolist()\n",
    "            print(f\"Misclassified indices: {misclassified_indices}\")\n",
    "            print(f\"Misclassified data: \")\n",
    "            for response in misclassified_data['response']:\n",
    "                print(response)\n",
    "   \n",
    "\n",
    "    # Convert results to a DataFrame and sort\n",
    "    country_results_df = custom_sort(pd.DataFrame(country_results))\n",
    "    \n",
    "    # # Apply highlighting and ensuring truncation\n",
    "    country_results_df = country_results_df.style.apply(highlight_row, axis=1).format(precision=2)\n",
    "    \n",
    "    # only select rows with the races being 'total'\n",
    "    if not race_verbose:\n",
    "        country_results_df = country_results_df[country_results_df['Race'] == 'Synthesized Total']\n",
    "                \n",
    "\n",
    "    return country_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can provide a csv file with response data for\n",
    "- original images of a single country/ multiple countries (eg. `images/Korea_Original_Food_Results.csv`)\n",
    "- synthesized images of a single country/ multiple countries (eg. `responses/internVL/internVL_master_synthesized_food.csv`)\n",
    "- original + synthesized images of a single country/multiple countries (eg. `responses/gpt4o/gpt4o_master_clothes.csv`)\n",
    "\n",
    "Rows for original iamges are highlighted red, and rows for total are highlighted green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4b72_row0_col0, #T_d4b72_row0_col1, #T_d4b72_row0_col2, #T_d4b72_row0_col3, #T_d4b72_row0_col4 {\n",
       "  background-color: #690150;\n",
       "}\n",
       "#T_d4b72_row5_col0, #T_d4b72_row5_col1, #T_d4b72_row5_col2, #T_d4b72_row5_col3, #T_d4b72_row5_col4 {\n",
       "  background-color: #016950;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4b72\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4b72_level0_col0\" class=\"col_heading level0 col0\" >Country</th>\n",
       "      <th id=\"T_d4b72_level0_col1\" class=\"col_heading level0 col1\" >Race</th>\n",
       "      <th id=\"T_d4b72_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_d4b72_level0_col3\" class=\"col_heading level0 col3\" >Correct Samples</th>\n",
       "      <th id=\"T_d4b72_level0_col4\" class=\"col_heading level0 col4\" >Total Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4b72_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4b72_row0_col0\" class=\"data row0 col0\" >US</td>\n",
       "      <td id=\"T_d4b72_row0_col1\" class=\"data row0 col1\" >US</td>\n",
       "      <td id=\"T_d4b72_row0_col2\" class=\"data row0 col2\" >0.91</td>\n",
       "      <td id=\"T_d4b72_row0_col3\" class=\"data row0 col3\" >30</td>\n",
       "      <td id=\"T_d4b72_row0_col4\" class=\"data row0 col4\" >33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4b72_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d4b72_row1_col0\" class=\"data row1 col0\" >US</td>\n",
       "      <td id=\"T_d4b72_row1_col1\" class=\"data row1 col1\" >African</td>\n",
       "      <td id=\"T_d4b72_row1_col2\" class=\"data row1 col2\" >0.97</td>\n",
       "      <td id=\"T_d4b72_row1_col3\" class=\"data row1 col3\" >32</td>\n",
       "      <td id=\"T_d4b72_row1_col4\" class=\"data row1 col4\" >33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4b72_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d4b72_row2_col0\" class=\"data row2 col0\" >US</td>\n",
       "      <td id=\"T_d4b72_row2_col1\" class=\"data row2 col1\" >Caucasian</td>\n",
       "      <td id=\"T_d4b72_row2_col2\" class=\"data row2 col2\" >0.94</td>\n",
       "      <td id=\"T_d4b72_row2_col3\" class=\"data row2 col3\" >31</td>\n",
       "      <td id=\"T_d4b72_row2_col4\" class=\"data row2 col4\" >33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4b72_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d4b72_row3_col0\" class=\"data row3 col0\" >US</td>\n",
       "      <td id=\"T_d4b72_row3_col1\" class=\"data row3 col1\" >EastAsian</td>\n",
       "      <td id=\"T_d4b72_row3_col2\" class=\"data row3 col2\" >0.91</td>\n",
       "      <td id=\"T_d4b72_row3_col3\" class=\"data row3 col3\" >30</td>\n",
       "      <td id=\"T_d4b72_row3_col4\" class=\"data row3 col4\" >33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4b72_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d4b72_row4_col0\" class=\"data row4 col0\" >US</td>\n",
       "      <td id=\"T_d4b72_row4_col1\" class=\"data row4 col1\" >SouthAsian</td>\n",
       "      <td id=\"T_d4b72_row4_col2\" class=\"data row4 col2\" >0.88</td>\n",
       "      <td id=\"T_d4b72_row4_col3\" class=\"data row4 col3\" >29</td>\n",
       "      <td id=\"T_d4b72_row4_col4\" class=\"data row4 col4\" >33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4b72_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d4b72_row5_col0\" class=\"data row5 col0\" >US</td>\n",
       "      <td id=\"T_d4b72_row5_col1\" class=\"data row5 col1\" >Synthesized Total</td>\n",
       "      <td id=\"T_d4b72_row5_col2\" class=\"data row5 col2\" >0.92</td>\n",
       "      <td id=\"T_d4b72_row5_col3\" class=\"data row5 col3\" >122</td>\n",
       "      <td id=\"T_d4b72_row5_col4\" class=\"data row5 col4\" >132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b1a2aaf1e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = '../responses/glm4v/US_Food_Results.csv'\n",
    "results_df = cultural_identification_metrics(file_path, race_verbose=True, misclassified_verbose=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Identification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zhipuai import ZhipuAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GLM_MODEL_API_KEY = os.getenv('GLM_MODEL_API_KEY')\n",
    "client = ZhipuAI(api_key=GLM_MODEL_API_KEY)\n",
    "\n",
    "# Define the function\n",
    "def heuristics_match_label(row):\n",
    "    terms = [term.lower().strip() for term in row['label'].split(',')]\n",
    "    if any(term in row['response'].lower() for term in terms):\n",
    "        #     print(f\"Filename: {row['image_file_name']} Matched: {terms} in {row['response']}\")\n",
    "            return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def ai_match_label(row):\n",
    "        system = '''\n",
    "        You'll be provided with a label and a response by a multi-modal LLM that identifies the name of the food in a picture. \n",
    "        Your task is to determine whether the food name contained in the response can be considered as correct given the ground-truth label. \n",
    "        under label. Consider it as correct ('Yes') if you think both refers to the same food semantically either in native language or in English.\n",
    "        Otherwise, 'No'. They don't need to match exactly, but if the answer is too generic, don't accept either. Answer only 'Yes' or 'No'.\n",
    "        '''\n",
    "        prompt = f'System: {system} | Response: {row['response']} | Label: {row['label']}'\n",
    "\n",
    "        answer = client.chat.completions.create(\n",
    "                model='glm-4-plus',\n",
    "                messages=[\n",
    "                {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                        {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt,                                \n",
    "                        },\n",
    "                        ],\n",
    "                }\n",
    "                ],\n",
    "                max_tokens=10,\n",
    "        )\n",
    "        \n",
    "        if answer.choices[0].message.content.lower() == 'yes':\n",
    "                # print(f'File: {row['image_file_name']} | Label: {row['label']} |  Response: {row['response']}')\n",
    "                return 1\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_identification_metrics(file_path, race, master_label_df=None, misclassified_verbose=False):        \n",
    "        data = pd.read_csv(file_path)\n",
    "        assert race in ['original', 'African', 'EastAsian', 'SouthAsian', 'Caucasian'], \"Invalid race value. Choose from 'original', 'Asian', 'Black', 'White', 'Indian', 'Caucasian'\"\n",
    "        \n",
    "        # drop rows whose race doesn't match with race parameter\n",
    "        if race == 'original':\n",
    "                data = data[~data['synthesized_race'].isin(['African', 'EastAsian', 'SouthAsian', 'Caucasian'])]\n",
    "        else:\n",
    "                data = data[data['synthesized_race'] == race]\n",
    "\n",
    "        try:\n",
    "                data['Match_label'] = data.apply(ai_match_label,axis=1)\n",
    "                data['label'] = data['label'].apply(lambda x: ', '.join(sorted(set(term.strip() for term in x.split(',')))))\n",
    "        except KeyError:\n",
    "                print(f\"Label column not found in the given response csv file. Ensure that the file is for food data and there is a column named 'label'.\")\n",
    "                return None\n",
    "\n",
    "        label_results = []\n",
    "        misclassified_images = []\n",
    "        unique_labels = data['label'].unique()\n",
    "\n",
    "        for lbl in unique_labels:\n",
    "                label_data = data[data['label'] == lbl]\n",
    "                y_true = [1] * len(label_data)  \n",
    "                y_pred = label_data['Match_label'].tolist()\n",
    "\n",
    "                precision, recall, f1, accuracy = calculate_scores(y_true, y_pred)\n",
    "                \n",
    "                # Identify misclassified samples\n",
    "                misclassified_indices = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true != pred]\n",
    "                \n",
    "                # get the file image names of misclassified samples\n",
    "                misclassified_images.extend(label_data.iloc[misclassified_indices]['image_file_name'].tolist())\n",
    "                \n",
    "                label_results.append({\n",
    "                'Label': lbl,\n",
    "                'Total Samples': len(label_data),\n",
    "                race: accuracy,\n",
    "                'Correct Samples': sum(y_pred),\n",
    "                })\n",
    "        \n",
    "        total_misclassified_images.extend(misclassified_images)\n",
    "        \n",
    "        if misclassified_verbose:\n",
    "                misclassified_data = data[data['image_file_name'].isin(misclassified_images)]\n",
    "                misclassified_indices = misclassified_data.index.tolist()\n",
    "                print(f\"Misclassified indices: {misclassified_indices}\")\n",
    "                print(f\"Misclassified data:\\n {misclassified_data}\")\n",
    "        # Convert label results to a DataFrame\n",
    "        label_results_df = pd.DataFrame(label_results)\n",
    "\n",
    "        # Calculate totals using pandas methods\n",
    "        totals = pd.Series({\n",
    "                'Label': 'total',\n",
    "                'Total Samples': label_results_df['Total Samples'].sum(),\n",
    "                race: round(label_results_df['Correct Samples'].sum() / label_results_df['Total Samples'].sum(), 3),\n",
    "                'Correct Samples': label_results_df['Correct Samples'].sum(),\n",
    "        })\n",
    "\n",
    "        # Append totals row to the DataFrame\n",
    "        label_results_df = pd.concat([label_results_df, pd.DataFrame([totals])], ignore_index=True)\n",
    "        # drop correct samples column\n",
    "        label_results_df = label_results_df.drop(columns='Correct Samples')\n",
    "        # if there is master label df to be combined with label_results_df, combine based on the 'Label' and  'Total samples' columns\n",
    "        if master_label_df is not None:\n",
    "                label_results_df = pd.merge(master_label_df, label_results_df, on=['Label', 'Total Samples'], how='outer')\n",
    "        \n",
    "        return label_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Invalid race value. Choose from 'original', 'Asian', 'Black', 'White', 'Indian', 'Caucasian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m total_misclassified_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m race \u001b[38;5;129;01min\u001b[39;00m races: \n\u001b[0;32m---> 10\u001b[0m     label_df \u001b[38;5;241m=\u001b[39m \u001b[43mfood_identification_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_label_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaster_label_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmisclassified_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     master_label_df \u001b[38;5;241m=\u001b[39m label_df\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# write total_misclassified_images to a txt file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mfood_identification_metrics\u001b[0;34m(file_path, race, master_label_df, misclassified_verbose)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfood_identification_metrics\u001b[39m(file_path, race\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m, master_label_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, misclassified_verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):        \n\u001b[1;32m      2\u001b[0m         data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m race \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCaucasian\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid race value. Choose from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsian\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhite\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndian\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCaucasian\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# drop rows whose race doesn't match with race parameter\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m race \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Invalid race value. Choose from 'original', 'Asian', 'Black', 'White', 'Indian', 'Caucasian'"
     ]
    }
   ],
   "source": [
    "model = 'internVL'\n",
    "category = 'US_Food'\n",
    "file_path = f'../responses/{model}/{category}_Results.csv'\n",
    "\n",
    "\n",
    "master_label_df = None\n",
    "total_misclassified_images = []\n",
    "races = ['original', 'African', 'EastAsian', 'SouthAsian', 'Caucasian']\n",
    "\n",
    "for race in races: \n",
    "    label_df = food_identification_metrics(file_path, race, master_label_df=master_label_df, misclassified_verbose=False)\n",
    "    master_label_df = label_df\n",
    "\n",
    "# write total_misclassified_images to a txt file\n",
    "with open(f'misclassified_food/{model}_{category}.txt', 'w') as f:\n",
    "    for item in total_misclassified_images:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "master_label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a request for each image\n",
    "def evaluate_response(client, prompt):\n",
    "    answer = client.chat.completions.create(\n",
    "        model='glm-4-plus',\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,                                \n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=100,\n",
    "    )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = ZhipuAI(api_key=GLM_MODEL_API_KEY)\n",
    "system = '''\n",
    "You'll be provided with a label and a response by a multi-modal LLM that identifies the name of the food in a picture. \n",
    "Your task is to determine whether the food name contained in the response can be considered as correct given the ground-truth label. \n",
    "under label. Consider it as correct ('Yes') if you think both refers to the same food semantically either in native language or in English.\n",
    "Otherwise, 'No'. They don't need to match exactly. Answer only 'Yes' or 'No'.\n",
    "'''\n",
    "response = \"The food in the photo is called \"\"Mee Goreng\"\" and it is mostly associated with Malaysia and Indonesia.\"\n",
    "label = 'Nan Gyi Thoke or Noodle salad,Khao Soi Thoke'\n",
    "prompt = f'System: {system} | Response: {response} | Label: {label}'\n",
    "answer = evaluate_response(client, prompt)\n",
    "answer.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
