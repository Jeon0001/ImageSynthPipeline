{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(y_true, y_pred, round_digits=2):\n",
    "    precision = round(precision_score(y_true, y_pred, zero_division=0), round_digits)\n",
    "    recall    = round(recall_score(y_true, y_pred, zero_division=0), round_digits)\n",
    "    f1        = round(f1_score(y_true, y_pred, zero_division=0), round_digits)\n",
    "    accuracy  = round(accuracy_score(y_true, y_pred), round_digits)\n",
    "    \n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "# Custom sorting function\n",
    "def custom_sort(df):\n",
    "    # Assign a priority column for sorting\n",
    "    df['priority'] = df.apply(\n",
    "        lambda row: 0 if row['Country'] == row['Race'] else 1 \n",
    "                    if row['Race'] != 'total' else 2, axis=1\n",
    "    )\n",
    "    # Sort by Country, then by priority, and reset index\n",
    "    df = df.sort_values(by=['Country', 'priority']).drop(columns='priority').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def highlight_row(row):\n",
    "    if row['Country'] == row['Race']:\n",
    "        return ['background-color: #690150'] * len(row) # data for original images are red\n",
    "    \n",
    "    if row['Race'] == 'total':\n",
    "        return ['background-color: #016950'] * len(row) # data for total images are green\n",
    "    \n",
    "    return [''] * len(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cultural Identification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cultural_identification_metrics(file_path, race_verbose=True, misclassified_verbose=False):\n",
    "    # 1. Load the data\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 2. Create 'Match' column. Match if `original_country` is mentioned in the `response`\n",
    "    data['Match_country'] = data.apply(\n",
    "        lambda row: 1 if any(term.lower().strip() in row['response'].lower() for term in row['original_country'].split(',')) else 0, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 3. Normalize the text of both `original_country` to ensure consistent grouping (e.g., remove duplicates, ordering effect, etc.)\n",
    "    data['original_country'] = data['original_country'].apply(lambda x: ', '.join(sorted(set(term.strip() for term in x.split(',')))))        \n",
    "\n",
    "    # Get unique combinations of country and race\n",
    "    unique_combinations = data.groupby(['original_country', 'synthesized_race']).size().reset_index()\n",
    "    unique_combinations.columns = ['original_country', 'synthesized_race', 'count']\n",
    "    \n",
    "    unique_countries = data['original_country'].unique()\n",
    "    \n",
    "    # Initialize results\n",
    "    country_results = []\n",
    "    misclassified_images = []\n",
    "        \n",
    "    # Add a row for the 'total'\n",
    "    for country in unique_countries:\n",
    "        # if there is only one synthesized_race for a country in unique_combinations, then skip adding 'total' row\n",
    "        if len(unique_combinations[unique_combinations['original_country'] == country]) > 1:\n",
    "            new_row = {'original_country': country, 'synthesized_race': 'total', 'count': 0}\n",
    "            unique_combinations = pd.concat([unique_combinations, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    # Compute metrics for each country-race combination\n",
    "    for index, row in unique_combinations.iterrows():\n",
    "        country = row['original_country']\n",
    "        race = row['synthesized_race']\n",
    "        \n",
    "        if race == 'total':\n",
    "            subset = data[(data['original_country'] == country) & (data['original_country'] != data['synthesized_race'])]\n",
    "        else:\n",
    "            subset = data[(data['original_country'] == country) & (data['synthesized_race'] == race)]\n",
    "        \n",
    "        y_true = [1] * len(subset)  # Ground truth: should mention the country\n",
    "        y_pred = subset['Match_country'].tolist()\n",
    "\n",
    "        precision, recall, f1, accuracy = calculate_scores(y_true, y_pred)                \n",
    "\n",
    "        # Identify misclassified samples\n",
    "        if race != 'total':\n",
    "            misclassified_indices = [i + (row['count'] * index) for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true != pred]  \n",
    "            misclassified_images.extend(data.iloc[misclassified_indices]['image_file_name'].tolist())\n",
    "                \n",
    "        country_results.append({\n",
    "            'Country': country,\n",
    "            'Race': race,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Accuracy': accuracy,\n",
    "            'Correct Samples': sum(y_pred),    # sum of 1s\n",
    "            'Total Samples': len(subset)      # total rows in this group\n",
    "        })\n",
    "\n",
    "    if misclassified_verbose:\n",
    "            print(f\"Misclassified images: {misclassified_images}\")\n",
    "            misclassified_data = data[data['image_file_name'].isin(misclassified_images)]\n",
    "            misclassified_indices = misclassified_data.index.tolist()\n",
    "            print(f\"Misclassified indices: {misclassified_indices}\")\n",
    "            print(f\"Misclassified data:\\n {misclassified_data}\")\n",
    "                \n",
    "    # Convert results to a DataFrame and sort\n",
    "    country_results_df = custom_sort(pd.DataFrame(country_results))\n",
    "    \n",
    "    # # Apply highlighting and ensuring truncation\n",
    "    country_results_df = country_results_df.style.apply(highlight_row, axis=1).format(precision=2)\n",
    "    \n",
    "    # only select rows with the races being 'total'\n",
    "    if not race_verbose:\n",
    "        country_results_df = country_results_df[country_results_df['Race'] == 'total']\n",
    "                \n",
    "\n",
    "    return country_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can provide a csv file with response data for\n",
    "- original images of a single country/ multiple countries (eg. `images/Korea_Original_Food_Results.csv`)\n",
    "- synthesized images of a single country/ multiple countries (eg. `responses/internVL/internVL_master_synthesized_food.csv`)\n",
    "- original + synthesized images of a single country/multiple countries (eg. `responses/gpt4o/gpt4o_master_clothes.csv`)\n",
    "\n",
    "Rows for original iamges are highlighted red, and rows for total are highlighted green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_88a58_row4_col0, #T_88a58_row4_col1, #T_88a58_row4_col2, #T_88a58_row4_col3, #T_88a58_row4_col4, #T_88a58_row4_col5, #T_88a58_row4_col6, #T_88a58_row4_col7, #T_88a58_row9_col0, #T_88a58_row9_col1, #T_88a58_row9_col2, #T_88a58_row9_col3, #T_88a58_row9_col4, #T_88a58_row9_col5, #T_88a58_row9_col6, #T_88a58_row9_col7, #T_88a58_row14_col0, #T_88a58_row14_col1, #T_88a58_row14_col2, #T_88a58_row14_col3, #T_88a58_row14_col4, #T_88a58_row14_col5, #T_88a58_row14_col6, #T_88a58_row14_col7 {\n",
       "  background-color: #016950;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_88a58\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_88a58_level0_col0\" class=\"col_heading level0 col0\" >Country</th>\n",
       "      <th id=\"T_88a58_level0_col1\" class=\"col_heading level0 col1\" >Race</th>\n",
       "      <th id=\"T_88a58_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_88a58_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_88a58_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
       "      <th id=\"T_88a58_level0_col5\" class=\"col_heading level0 col5\" >Accuracy</th>\n",
       "      <th id=\"T_88a58_level0_col6\" class=\"col_heading level0 col6\" >Correct Samples</th>\n",
       "      <th id=\"T_88a58_level0_col7\" class=\"col_heading level0 col7\" >Total Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_88a58_row0_col0\" class=\"data row0 col0\" >Korea</td>\n",
       "      <td id=\"T_88a58_row0_col1\" class=\"data row0 col1\" >Asian</td>\n",
       "      <td id=\"T_88a58_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row0_col3\" class=\"data row0 col3\" >0.85</td>\n",
       "      <td id=\"T_88a58_row0_col4\" class=\"data row0 col4\" >0.92</td>\n",
       "      <td id=\"T_88a58_row0_col5\" class=\"data row0 col5\" >0.85</td>\n",
       "      <td id=\"T_88a58_row0_col6\" class=\"data row0 col6\" >17</td>\n",
       "      <td id=\"T_88a58_row0_col7\" class=\"data row0 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_88a58_row1_col0\" class=\"data row1 col0\" >Korea</td>\n",
       "      <td id=\"T_88a58_row1_col1\" class=\"data row1 col1\" >Black</td>\n",
       "      <td id=\"T_88a58_row1_col2\" class=\"data row1 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row1_col3\" class=\"data row1 col3\" >0.80</td>\n",
       "      <td id=\"T_88a58_row1_col4\" class=\"data row1 col4\" >0.89</td>\n",
       "      <td id=\"T_88a58_row1_col5\" class=\"data row1 col5\" >0.80</td>\n",
       "      <td id=\"T_88a58_row1_col6\" class=\"data row1 col6\" >16</td>\n",
       "      <td id=\"T_88a58_row1_col7\" class=\"data row1 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_88a58_row2_col0\" class=\"data row2 col0\" >Korea</td>\n",
       "      <td id=\"T_88a58_row2_col1\" class=\"data row2 col1\" >Indian</td>\n",
       "      <td id=\"T_88a58_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row2_col3\" class=\"data row2 col3\" >0.75</td>\n",
       "      <td id=\"T_88a58_row2_col4\" class=\"data row2 col4\" >0.86</td>\n",
       "      <td id=\"T_88a58_row2_col5\" class=\"data row2 col5\" >0.75</td>\n",
       "      <td id=\"T_88a58_row2_col6\" class=\"data row2 col6\" >15</td>\n",
       "      <td id=\"T_88a58_row2_col7\" class=\"data row2 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_88a58_row3_col0\" class=\"data row3 col0\" >Korea</td>\n",
       "      <td id=\"T_88a58_row3_col1\" class=\"data row3 col1\" >White</td>\n",
       "      <td id=\"T_88a58_row3_col2\" class=\"data row3 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row3_col3\" class=\"data row3 col3\" >0.80</td>\n",
       "      <td id=\"T_88a58_row3_col4\" class=\"data row3 col4\" >0.89</td>\n",
       "      <td id=\"T_88a58_row3_col5\" class=\"data row3 col5\" >0.80</td>\n",
       "      <td id=\"T_88a58_row3_col6\" class=\"data row3 col6\" >16</td>\n",
       "      <td id=\"T_88a58_row3_col7\" class=\"data row3 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_88a58_row4_col0\" class=\"data row4 col0\" >Korea</td>\n",
       "      <td id=\"T_88a58_row4_col1\" class=\"data row4 col1\" >total</td>\n",
       "      <td id=\"T_88a58_row4_col2\" class=\"data row4 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row4_col3\" class=\"data row4 col3\" >0.80</td>\n",
       "      <td id=\"T_88a58_row4_col4\" class=\"data row4 col4\" >0.89</td>\n",
       "      <td id=\"T_88a58_row4_col5\" class=\"data row4 col5\" >0.80</td>\n",
       "      <td id=\"T_88a58_row4_col6\" class=\"data row4 col6\" >64</td>\n",
       "      <td id=\"T_88a58_row4_col7\" class=\"data row4 col7\" >80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_88a58_row5_col0\" class=\"data row5 col0\" >Myanmar</td>\n",
       "      <td id=\"T_88a58_row5_col1\" class=\"data row5 col1\" >Asian</td>\n",
       "      <td id=\"T_88a58_row5_col2\" class=\"data row5 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row5_col3\" class=\"data row5 col3\" >0.05</td>\n",
       "      <td id=\"T_88a58_row5_col4\" class=\"data row5 col4\" >0.10</td>\n",
       "      <td id=\"T_88a58_row5_col5\" class=\"data row5 col5\" >0.05</td>\n",
       "      <td id=\"T_88a58_row5_col6\" class=\"data row5 col6\" >1</td>\n",
       "      <td id=\"T_88a58_row5_col7\" class=\"data row5 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_88a58_row6_col0\" class=\"data row6 col0\" >Myanmar</td>\n",
       "      <td id=\"T_88a58_row6_col1\" class=\"data row6 col1\" >Black</td>\n",
       "      <td id=\"T_88a58_row6_col2\" class=\"data row6 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row6_col3\" class=\"data row6 col3\" >0.05</td>\n",
       "      <td id=\"T_88a58_row6_col4\" class=\"data row6 col4\" >0.10</td>\n",
       "      <td id=\"T_88a58_row6_col5\" class=\"data row6 col5\" >0.05</td>\n",
       "      <td id=\"T_88a58_row6_col6\" class=\"data row6 col6\" >1</td>\n",
       "      <td id=\"T_88a58_row6_col7\" class=\"data row6 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_88a58_row7_col0\" class=\"data row7 col0\" >Myanmar</td>\n",
       "      <td id=\"T_88a58_row7_col1\" class=\"data row7 col1\" >Indian</td>\n",
       "      <td id=\"T_88a58_row7_col2\" class=\"data row7 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row7_col3\" class=\"data row7 col3\" >0.05</td>\n",
       "      <td id=\"T_88a58_row7_col4\" class=\"data row7 col4\" >0.10</td>\n",
       "      <td id=\"T_88a58_row7_col5\" class=\"data row7 col5\" >0.05</td>\n",
       "      <td id=\"T_88a58_row7_col6\" class=\"data row7 col6\" >1</td>\n",
       "      <td id=\"T_88a58_row7_col7\" class=\"data row7 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_88a58_row8_col0\" class=\"data row8 col0\" >Myanmar</td>\n",
       "      <td id=\"T_88a58_row8_col1\" class=\"data row8 col1\" >White</td>\n",
       "      <td id=\"T_88a58_row8_col2\" class=\"data row8 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row8_col3\" class=\"data row8 col3\" >0.05</td>\n",
       "      <td id=\"T_88a58_row8_col4\" class=\"data row8 col4\" >0.10</td>\n",
       "      <td id=\"T_88a58_row8_col5\" class=\"data row8 col5\" >0.05</td>\n",
       "      <td id=\"T_88a58_row8_col6\" class=\"data row8 col6\" >1</td>\n",
       "      <td id=\"T_88a58_row8_col7\" class=\"data row8 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_88a58_row9_col0\" class=\"data row9 col0\" >Myanmar</td>\n",
       "      <td id=\"T_88a58_row9_col1\" class=\"data row9 col1\" >total</td>\n",
       "      <td id=\"T_88a58_row9_col2\" class=\"data row9 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row9_col3\" class=\"data row9 col3\" >0.05</td>\n",
       "      <td id=\"T_88a58_row9_col4\" class=\"data row9 col4\" >0.10</td>\n",
       "      <td id=\"T_88a58_row9_col5\" class=\"data row9 col5\" >0.05</td>\n",
       "      <td id=\"T_88a58_row9_col6\" class=\"data row9 col6\" >4</td>\n",
       "      <td id=\"T_88a58_row9_col7\" class=\"data row9 col7\" >80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_88a58_row10_col0\" class=\"data row10 col0\" >UK</td>\n",
       "      <td id=\"T_88a58_row10_col1\" class=\"data row10 col1\" >Asian</td>\n",
       "      <td id=\"T_88a58_row10_col2\" class=\"data row10 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row10_col3\" class=\"data row10 col3\" >0.05</td>\n",
       "      <td id=\"T_88a58_row10_col4\" class=\"data row10 col4\" >0.10</td>\n",
       "      <td id=\"T_88a58_row10_col5\" class=\"data row10 col5\" >0.05</td>\n",
       "      <td id=\"T_88a58_row10_col6\" class=\"data row10 col6\" >1</td>\n",
       "      <td id=\"T_88a58_row10_col7\" class=\"data row10 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_88a58_row11_col0\" class=\"data row11 col0\" >UK</td>\n",
       "      <td id=\"T_88a58_row11_col1\" class=\"data row11 col1\" >Black</td>\n",
       "      <td id=\"T_88a58_row11_col2\" class=\"data row11 col2\" >0.00</td>\n",
       "      <td id=\"T_88a58_row11_col3\" class=\"data row11 col3\" >0.00</td>\n",
       "      <td id=\"T_88a58_row11_col4\" class=\"data row11 col4\" >0.00</td>\n",
       "      <td id=\"T_88a58_row11_col5\" class=\"data row11 col5\" >0.00</td>\n",
       "      <td id=\"T_88a58_row11_col6\" class=\"data row11 col6\" >0</td>\n",
       "      <td id=\"T_88a58_row11_col7\" class=\"data row11 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_88a58_row12_col0\" class=\"data row12 col0\" >UK</td>\n",
       "      <td id=\"T_88a58_row12_col1\" class=\"data row12 col1\" >Indian</td>\n",
       "      <td id=\"T_88a58_row12_col2\" class=\"data row12 col2\" >0.00</td>\n",
       "      <td id=\"T_88a58_row12_col3\" class=\"data row12 col3\" >0.00</td>\n",
       "      <td id=\"T_88a58_row12_col4\" class=\"data row12 col4\" >0.00</td>\n",
       "      <td id=\"T_88a58_row12_col5\" class=\"data row12 col5\" >0.00</td>\n",
       "      <td id=\"T_88a58_row12_col6\" class=\"data row12 col6\" >0</td>\n",
       "      <td id=\"T_88a58_row12_col7\" class=\"data row12 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_88a58_row13_col0\" class=\"data row13 col0\" >UK</td>\n",
       "      <td id=\"T_88a58_row13_col1\" class=\"data row13 col1\" >White</td>\n",
       "      <td id=\"T_88a58_row13_col2\" class=\"data row13 col2\" >0.00</td>\n",
       "      <td id=\"T_88a58_row13_col3\" class=\"data row13 col3\" >0.00</td>\n",
       "      <td id=\"T_88a58_row13_col4\" class=\"data row13 col4\" >0.00</td>\n",
       "      <td id=\"T_88a58_row13_col5\" class=\"data row13 col5\" >0.00</td>\n",
       "      <td id=\"T_88a58_row13_col6\" class=\"data row13 col6\" >0</td>\n",
       "      <td id=\"T_88a58_row13_col7\" class=\"data row13 col7\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88a58_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_88a58_row14_col0\" class=\"data row14 col0\" >UK</td>\n",
       "      <td id=\"T_88a58_row14_col1\" class=\"data row14 col1\" >total</td>\n",
       "      <td id=\"T_88a58_row14_col2\" class=\"data row14 col2\" >1.00</td>\n",
       "      <td id=\"T_88a58_row14_col3\" class=\"data row14 col3\" >0.01</td>\n",
       "      <td id=\"T_88a58_row14_col4\" class=\"data row14 col4\" >0.02</td>\n",
       "      <td id=\"T_88a58_row14_col5\" class=\"data row14 col5\" >0.01</td>\n",
       "      <td id=\"T_88a58_row14_col6\" class=\"data row14 col6\" >1</td>\n",
       "      <td id=\"T_88a58_row14_col7\" class=\"data row14 col7\" >80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d1e3e4f1b80>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file_path = '../responses/gpt4o/gpt4o_master_clothes.csv'\n",
    "file_path = '../responses/internVL/internVL_master_synthesized_food.csv'\n",
    "# file_path = '../images/Korean_Food/Korea_Synthesized_Food_Results.csv'\n",
    "results_df = cultural_identification_metrics(file_path, race_verbose=True, misclassified_verbose=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Identification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_identification_metrics(file_path, race='original', misclassified_verbose=False):        \n",
    "        data = pd.read_csv(file_path)\n",
    "        assert race in ['original', 'Asian', 'Black', 'White', 'Indian', 'Caucasian'], \"Invalid race value. Choose from 'original', 'Asian', 'Black', 'White', 'Indian', 'Caucasian'\"\n",
    "        \n",
    "        # drop rows whose race doesn't match with race parameter\n",
    "        if race == 'original':\n",
    "                data = data[data['synthesized_race'] == data['original_country']]\n",
    "        else:\n",
    "                data = data[data['synthesized_race'] == race]\n",
    "\n",
    "        try:\n",
    "                data['Match_label'] = data.apply(\n",
    "                                lambda row: 1 if any(term.lower().strip() in row['response'].lower() for term in row['label'].split(',')) else 0, \n",
    "                                axis=1\n",
    "                        )\n",
    "\n",
    "                data['label'] = data['label'].apply(lambda x: ', '.join(sorted(set(term.strip() for term in x.split(',')))))\n",
    "        except KeyError:\n",
    "                print(f\"Label column not found in the given response csv file. Ensure that the file is for food data and there is a column named 'label'.\")\n",
    "                return None\n",
    "\n",
    "        label_results = []\n",
    "        misclassified_images = []\n",
    "        unique_labels = data['label'].unique()\n",
    "\n",
    "        for lbl in unique_labels:\n",
    "                label_data = data[data['label'] == lbl]\n",
    "                y_true = [1] * len(label_data)  # ground truth: should mention the label\n",
    "                y_pred = label_data['Match_label'].tolist()\n",
    "\n",
    "                precision, recall, f1, accuracy = calculate_scores(y_true, y_pred)\n",
    "\n",
    "                # Identify misclassified samples\n",
    "                misclassified_indices = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true != pred]\n",
    "                \n",
    "                # get the file image names of misclassified samples\n",
    "                misclassified_images.extend(label_data.iloc[misclassified_indices]['image_file_name'].tolist())\n",
    "                \n",
    "                label_results.append({\n",
    "                'Label': lbl,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1 Score': f1,\n",
    "                'Accuracy': accuracy,\n",
    "                'Correct Samples': sum(y_pred),\n",
    "                'Total Samples': len(label_data)\n",
    "                })\n",
    "        \n",
    "        if misclassified_verbose:\n",
    "                misclassified_data = data[data['image_file_name'].isin(misclassified_images)]\n",
    "                misclassified_indices = misclassified_data.index.tolist()\n",
    "                print(f\"Misclassified indices: {misclassified_indices}\")\n",
    "                print(f\"Misclassified data:\\n {misclassified_data}\")\n",
    "        # Convert label results to a DataFrame\n",
    "        label_results_df = pd.DataFrame(label_results)\n",
    "\n",
    "        # Calculate totals using pandas methods\n",
    "        totals = pd.Series({\n",
    "                'Label': 'total',\n",
    "                'Precision': (label_results_df['Correct Samples'].sum() / label_results_df['Total Samples'].sum()),\n",
    "                'Recall': (label_results_df['Correct Samples'].sum() / label_results_df['Total Samples'].sum()),\n",
    "                'F1 Score': (label_results_df['Correct Samples'].sum() / label_results_df['Total Samples'].sum()),  # Same as precision/recall in this case\n",
    "                'Accuracy': (label_results_df['Correct Samples'].sum() / label_results_df['Total Samples'].sum()),\n",
    "                'Correct Samples': label_results_df['Correct Samples'].sum(),\n",
    "                'Total Samples': label_results_df['Total Samples'].sum()\n",
    "        })\n",
    "\n",
    "        # Append totals row to the DataFrame\n",
    "        label_results_df = pd.concat([label_results_df, pd.DataFrame([totals])], ignore_index=True)\n",
    "        \n",
    "        return label_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified indices: [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 19]\n",
      "Misclassified data:\n",
      "    original_country synthesized_race      image_file_name  \\\n",
      "1           Myanmar          Myanmar   Myanmar_food_1.png   \n",
      "2           Myanmar          Myanmar   Myanmar_food_2.png   \n",
      "4           Myanmar          Myanmar   Myanmar_food_4.png   \n",
      "5           Myanmar          Myanmar   Myanmar_food_5.png   \n",
      "6           Myanmar          Myanmar   Myanmar_food_6.png   \n",
      "7           Myanmar          Myanmar   Myanmar_food_7.png   \n",
      "8           Myanmar          Myanmar   Myanmar_food_8.png   \n",
      "9           Myanmar          Myanmar   Myanmar_food_9.png   \n",
      "10          Myanmar          Myanmar  Myanmar_food_10.png   \n",
      "11          Myanmar          Myanmar  Myanmar_food_11.png   \n",
      "12          Myanmar          Myanmar  Myanmar_food_12.png   \n",
      "16          Myanmar          Myanmar  Myanmar_food_16.png   \n",
      "17          Myanmar          Myanmar  Myanmar_food_17.png   \n",
      "19          Myanmar          Myanmar  Myanmar_food_19.png   \n",
      "\n",
      "                                                label  \\\n",
      "1                        Laphet Thoke, Tea leaf salad   \n",
      "2   Mohinga, fish broth, fish soup, fish-based bro...   \n",
      "4                        Laphet Thoke, Tea leaf salad   \n",
      "5   Dote Htoe, Wat Thar Dote Htoe, pork offal skew...   \n",
      "6   Dote Htoe, Wat Thar Dote Htoe, pork offal skew...   \n",
      "7   Ohn No Khao Swe, coconut curry, coconut curry ...   \n",
      "8   Burmese cuisine, Burmese curry, Myanmar cuisin...   \n",
      "9   Dote Htoe, Wat Thar Dote Htoe, pork offal skew...   \n",
      "10  Mohinga, fish broth, fish soup, fish-based bro...   \n",
      "11  Dote Htoe, Wat Thar Dote Htoe, pork offal skew...   \n",
      "12        Khao Soi Thoke, Nan Gyi Thoke, Noodle salad   \n",
      "16  Mohinga, fish broth, fish soup, fish-based bro...   \n",
      "17  Mohinga, fish broth, fish soup, fish-based bro...   \n",
      "19  Mohinga, fish broth, fish soup, fish-based bro...   \n",
      "\n",
      "                                             response  Match_label  \n",
      "1   The food in the photo is mostly associated wit...            0  \n",
      "2   The food in the photo is associated with Myanm...            0  \n",
      "4   The food in the photo is mostly associated wit...            0  \n",
      "5   The food in the photo is mostly associated wit...            0  \n",
      "6   This dish is mostly associated with Myanmar, a...            0  \n",
      "7   The food in the photo is mostly associated wit...            0  \n",
      "8   The food in the photo appears to be associated...            0  \n",
      "9   This food is mostly associated with China and ...            0  \n",
      "10  The food in the photo is mostly associated wit...            0  \n",
      "11  The food in the photo is mostly associated wit...            0  \n",
      "12  The food in the photo is called \"Mee Goreng\" a...            0  \n",
      "16  The food in the photo is mostly associated wit...            0  \n",
      "17  The food in the photo is called \"Khao Soi,\" an...            0  \n",
      "19  The food in the photo is mostly associated wit...            0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Correct Samples</th>\n",
       "      <th>Total Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burmese cuisine, Burmese curry, Myanmar cuisin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laphet Thoke, Tea leaf salad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohinga, fish broth, fish soup, fish-based bro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dote Htoe, Wat Thar Dote Htoe, pork offal skew...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ohn No Khao Swe, coconut curry, coconut curry ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Khao Soi Thoke, Nan Gyi Thoke, Noodle salad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Label  Precision  Recall  \\\n",
       "0  Burmese cuisine, Burmese curry, Myanmar cuisin...        1.0    0.50   \n",
       "1                       Laphet Thoke, Tea leaf salad        1.0    0.33   \n",
       "2  Mohinga, fish broth, fish soup, fish-based bro...        1.0    0.38   \n",
       "3  Dote Htoe, Wat Thar Dote Htoe, pork offal skew...        0.0    0.00   \n",
       "4  Ohn No Khao Swe, coconut curry, coconut curry ...        1.0    0.50   \n",
       "5        Khao Soi Thoke, Nan Gyi Thoke, Noodle salad        0.0    0.00   \n",
       "6                                              total        0.3    0.30   \n",
       "\n",
       "   F1 Score  Accuracy  Correct Samples  Total Samples  \n",
       "0      0.67      0.50                1              2  \n",
       "1      0.50      0.33                1              3  \n",
       "2      0.55      0.38                3              8  \n",
       "3      0.00      0.00                0              4  \n",
       "4      0.67      0.50                1              2  \n",
       "5      0.00      0.00                0              1  \n",
       "6      0.30      0.30                6             20  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../responses/gpt4o/Myanmar_Food_Results.csv'\n",
    "label_df = food_identification_metrics(file_path, race='original', misclassified_verbose=True)\n",
    "label_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
