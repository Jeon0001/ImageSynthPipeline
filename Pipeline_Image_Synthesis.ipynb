{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Packages\n",
    "Note Use Correct Kernel\n",
    "# IMPORTANT: PLEASE REFER TO README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers transformers accelerate scipy safetensors\n",
    "!pip install salesforce-lavis\n",
    "# (For Colab, if running locally, refer to README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from diffusers import StableDiffusionInpaintPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Folder Designations (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Setup\n",
    "parent_folder = \"images\"\n",
    "input_folder = os.path.join(parent_folder, \"input_images\")\n",
    "mask_folder = os.path.join(parent_folder, \"mask_images\")\n",
    "output_folder = os.path.join(parent_folder, \"output_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = True\n",
    "\n",
    "if using_colab:\n",
    "    if not os.path.isdir(parent_folder):\n",
    "        !mkdir -p $parent_folder\n",
    "    !unzip -d $parent_folder input_images.zip \n",
    "    !unzip -d $parent_folder mask_images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Folder Designations (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Setup\n",
    "input_folder = \"folder_path_for_input_images\"\n",
    "mask_folder = \"folder_path_for_mask_images\"\n",
    "output_folder = \"folder_path_for_result_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mask Image Folder Generation\n",
    "##### Note: White = Area to Inpaint\n",
    "- Input images should be 3-channel images with resolution 512x512\n",
    "- Save masks to \"mask_folder\" with names corresponding to the input images + \"_mask\"\n",
    "- Masks should be 1-channel images with the same size as the input images (greyscale, resolution 512x512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creation of Synthesized Images\n",
    "##### Suggesting: Creation of autoprompter, perhaps another model(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    torch_dtype = torch.float16,\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "#########\n",
    "# Set Prompt Here\n",
    "prompt = \"(e.g.) Traditional fisherman fishing on a large lake.\"\n",
    "#########\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through the images in the input folder\n",
    "for image_filename in sorted(os.listdir(input_folder)):\n",
    "    if image_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Construct full file paths\n",
    "        image_path = os.path.join(input_folder, image_filename)\n",
    "        mask_filename = os.path.splitext(image_filename)[0] + \"_mask.png\"\n",
    "        mask_path = os.path.join(mask_folder, mask_filename)\n",
    "        \n",
    "        # Check if the corresponding mask exists\n",
    "        if os.path.exists(mask_path):\n",
    "            # Open the images\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            mask_image = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "            # Ensure the mask size matches the image size\n",
    "            if image.size != mask_image.size:\n",
    "                print(f\"Resizing mask for {image_filename} to match the image size.\")\n",
    "                mask_image = mask_image.resize(image.size)\n",
    "\n",
    "            # Perform inpainting\n",
    "            inpainted_image = pipe(prompt=prompt, image=image, mask_image=mask_image).images[0]\n",
    "\n",
    "            # Save the inpainted image\n",
    "            output_filename = os.path.splitext(image_filename)[0] + \"_inpainted.png\"\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            inpainted_image.save(output_path)\n",
    "            print(f\"Saved inpainted image to {output_path}\")\n",
    "        else:\n",
    "            print(f\"Mask for {image_filename} not found. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. VQA Testing\n",
    "(BLIP VQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "from PIL import Image\n",
    "from lavis.models import load_model_and_preprocess\n",
    "\n",
    "# setup device to use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the VQA model and preprocessing tools\n",
    "model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip_vqa\", model_type=\"vqav2\", is_eval=True, device=device)\n",
    "\n",
    "# define the question for the VQA\n",
    "question_text = \"What country is this food from?\"\n",
    "\n",
    "# folder containing images\n",
    "# output_folder\n",
    "\n",
    "# folder to save the CSV file\n",
    "csv_output_path = \"path to save BLIP-VQA responses\"\n",
    "\n",
    "\n",
    "# initialize the CSV file and write headers\n",
    "with open(csv_output_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Image File', 'VQA Response'])\n",
    "\n",
    "    # iterate through all images in the output folder\n",
    "    for image_file in os.listdir(output_folder):\n",
    "        # only process image files\n",
    "        if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # load and process the image\n",
    "            image_path = os.path.join(output_folder, image_file)\n",
    "            raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "            image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
    "            \n",
    "            # process the question\n",
    "            question = txt_processors[\"eval\"](question_text)\n",
    "            \n",
    "            # get the model's prediction\n",
    "            response = model.predict_answers(samples={\"image\": image, \"text_input\": question}, inference_method=\"generate\")\n",
    "            \n",
    "            # write the image filename and model response to the CSV\n",
    "            writer.writerow([image_file, response[0]])  # response[0] to get the answer\n",
    "\n",
    "print(f\"VQA responses saved to {csv_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stability-inpaint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
